{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1deb21-6561-454a-9abd-7fc926c15fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 4317\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "import glob\n",
    "import pickle  # Correct import statement\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Define function to load images using Pillow library\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "# Load the pretrained ResNet-50 model\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "model.eval()\n",
    "# Get preprocessing object for image\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Define whether to use precomputed embeddings (features) of images\n",
    "use_precomputed_embeddings = True\n",
    "emb_filename = 'C:/content/flower_images_embs.pickle'\n",
    "img_folder = 'C:/content/flowers'\n",
    "\n",
    "if use_precomputed_embeddings:\n",
    "    # If embeddings are already computed, load them from the pickle file\n",
    "    with open(emb_filename, 'rb') as fIn:\n",
    "        img_names, img_emb_tensors = pickle.load(fIn)\n",
    "    print(\"Images:\", len(img_names))\n",
    "else:\n",
    "    # If embeddings are not computed, extract features from images\n",
    "    img_names = list(glob.glob(img_folder + '/*/*.jpg'))\n",
    "    img_emb = []\n",
    "    # Extract features from images in the dataset (approximately 1 hour)\n",
    "    for image in tqdm(img_names):\n",
    "        img_emb.append(\n",
    "            model(preprocess(pil_loader(image)).unsqueeze(0)).squeeze(0).detach().numpy()\n",
    "        )\n",
    "    img_emb_tensors = torch.tensor(img_emb)\n",
    "    \n",
    "    # Save the embeddings to a pickle file for later use\n",
    "    with open(emb_filename, 'wb') as handle:\n",
    "        pickle.dump([img_names, img_emb_tensors], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0f2c2d-1a50-46a5-b9e6-373bfed94b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"apt\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\adrev\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!apt install libomp-dev \n",
    "!pip install faiss-cpu\n",
    "import faiss\n",
    "from sklearn.decomposition import PCA # (PCA - principal component analysis / Анализ главныX компонентов)\n",
    "# Функция собирает индекс и предварительно уменьшаяет размерность векторов\n",
    "def build_compressed_index(n_features):\n",
    "    pca = PCA(n_components=n_features)\n",
    "    pca.fit(img_emb_tensors)\n",
    "    compressed_features = pca.transform (img_emb_tensors)\n",
    "    dataset = np.float32(compressed_features)\n",
    "    d = dataset.shape[1] # dimension \n",
    "    nb = dataset.shape[0] # database size\n",
    "    xb = dataset\n",
    "    index_compressed = faiss.IndexFlatL2(d) # build the index\n",
    "    index_compressed.add(xb) # add vectors to the index\n",
    "    return [pca, index_compressed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d930eb81-3c9f-4dd3-8258-9cbc7e9d570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Хэлперы для отображения изображений \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mping\n",
    "\n",
    "def main_image(img_path, desc):\n",
    "    plt.imshow(mping.imread(ing_path))\n",
    "    plt.xlabel(img_path.split('.')[0] + '_Original Image', fontsize=12) \n",
    "    plt.title(desc, fontsize=20)\n",
    "    plt.show()\n",
    "               \n",
    "def similar_images (indices, suptitle):\n",
    "    plt.figure(figsize=(15,10), facecolor='white')\n",
    "    plotnumber = 1\n",
    "    for index in indices [0:4]:\n",
    "        if plotnumber<-len(indices) :\n",
    "            ax = plt.subplot(2,2,plotnumber)\n",
    "            plt.imshow(mping.imread(img_names[index]))\n",
    "            plt.xlabel(img_names[index], fontsize=12)\n",
    "            plotnumber+=1\n",
    "    plt.suptitle(suptitle, fontsize=15) \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb85df14-914b-4b39-9ea2-74c470d37efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# поиск, можно искать по индексу из предварительно извлеченных [изображений или передать новое изображение \n",
    "def search (query, factors):\n",
    "    if (type(query) == str):\n",
    "        img_path = query\n",
    "    else:\n",
    "        img_path = img_names[query]\n",
    "    one_img_emb = torch.tensor(model(preprocess(read_image(img_path))).unsqueeze(0).squeeze(0).detach().numpy())\n",
    "    main_image(img_path, 'Query')\n",
    "    compressor, index_compressed = build_compressed_index(factors)\n",
    "    D, I = index_compressed.search(np.float32(compressor.transform([one_img_emb.detach().numpy()])),5) \n",
    "    similar_images (I[0][1:], \"faiss compressed \" + str(factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd496539-97d2-4078-9f8b-89e6cf19c4af",
   "metadata": {},
   "source": [
    "img_names[250] это индекс 250 в списке имен файлов, которые были использованы для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d137b9-c3bf-4657-8ebd-348e116b4be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/flowers/rose/17062080069_36ac7907d2_n.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_names [250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120bb749-7c17-4075-b387-2c971731aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ImageNet-1K': {'acc@1': 80.858, 'acc@5': 95.434}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "metrics = weights.value.__dict__['meta']['_metrics'] \n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5b403-861e-4ecb-9c0a-84a335519a84",
   "metadata": {},
   "source": [
    "\"search(\"/content/flowers/daisy/13826249325_f61cb15f86_n.jpg\",300)\" - зто вызов функции \"search\" для поиска поxожиx изображений на \"/content/flowers/daisy/13826249325_f61cb15f86_n.jpg\" с использованием сжатого индекса с числом главных компонент равным 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104d6a9-2dd6-47ba-9485-d9cdeb97c4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ced24e-20b1-448f-8e10-888b1798d55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cbc73-75fc-4949-8a4b-27aba5231b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15228ac-5232-4aa3-9c83-a70615bf3dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
